{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary packages\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import hydra\n",
    "import dill\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "from diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    "from diffusion_policy.policy.diffusion_unet_hybrid_image_policy import DiffusionUnetHybridImagePolicy\n",
    "from diffusion_policy.dataset.robomimic_replay_image_dataset import BaseImageDataset\n",
    "from diffusion_policy.model.common.normalizer import LinearNormalizer, SingleFieldLinearNormalizer\n",
    "from diffusion_policy.common.pytorch_util import dict_apply, optimizer_to\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import functools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load workspace so that to get the (i) image dataset and (ii) vision encoder\n",
    "checkpoint  = \"../outputs/lift_image_ph_reproduction/2025.06.10_10.30.38_train_diffusion_unet_hybrid_lift_image/checkpoints/epoch=0050-test_mean_score=1.000.ckpt\"\n",
    "output_dir = checkpoint[:-5] # Remove '.ckpt' from checkpoint path\n",
    "\n",
    "payload = torch.load(open(checkpoint, 'rb'), pickle_module=dill)\n",
    "cfg = payload['cfg']\n",
    "cfg.training.device = \"cuda:1\"\n",
    "\n",
    "cls = hydra.utils.get_class(cfg._target_)\n",
    "workspace = cls(cfg, output_dir=output_dir)\n",
    "workspace: BaseWorkspace\n",
    "workspace.load_payload(payload, exclude_keys=None, include_keys=None)\n",
    "\n",
    "# get dataset\n",
    "image_dataset = hydra.utils.instantiate(cfg.task.dataset, dataset_path=os.path.join(\"../\", cfg.task.dataset.dataset_path))\n",
    "assert isinstance(image_dataset, BaseImageDataset)\n",
    "train_dataloader = DataLoader(image_dataset, **cfg.dataloader)\n",
    "\n",
    "# get model\n",
    "model = workspace.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get normalizer\n",
    "data_dict = {\"data\": list(), \"condition\": list()}\n",
    "\n",
    "for batch in tqdm(train_dataloader):\n",
    "    batch = dict_apply(batch, lambda x: x.to(cfg.training.device, non_blocking=True))\n",
    "    \n",
    "    obs_dict = batch[\"obs\"]\n",
    "    nobs_features = model.encode_obs(obs_dict)\n",
    "    data_dict[\"data\"].append(nobs_features.detach().cpu().clone())\n",
    "    data_dict[\"condition\"].append(batch[\"action\"][:, 1, :].detach().cpu().clone())\n",
    "    \n",
    "    # break;\n",
    "    \n",
    "    del batch # without del, the memory will be filled up\n",
    "\n",
    "data_dict[\"data\"] = torch.cat(data_dict[\"data\"], dim=0).detach().cpu().clone().numpy()\n",
    "data_dict[\"condition\"] = torch.cat(data_dict[\"condition\"], dim=0).detach().cpu().clone().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make normalizer\n",
    "data_normalizer = SingleFieldLinearNormalizer()\n",
    "data_normalizer.fit(data_dict[\"data\"], last_n_dims=1, mode='limits')\n",
    "\n",
    "condition_normalizer = SingleFieldLinearNormalizer()\n",
    "condition_normalizer.fit(data_dict[\"condition\"], last_n_dims=1, mode='limits')\n",
    "\n",
    "normalizer = LinearNormalizer()\n",
    "normalizer[\"data\"] = data_normalizer\n",
    "normalizer[\"condition\"] = condition_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = normalizer['data'].normalize(data_dict[\"data\"]).detach().cpu().numpy()\n",
    "plot_condition = normalizer['condition'].normalize(data_dict[\"condition\"]).detach().cpu().numpy()\n",
    "\n",
    "print(plot_data.shape)\n",
    "print(plot_condition.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDatasetWrapper(Dataset):\n",
    "    def __init__(self, dataset:Dict):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset[\"data\"])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\"data\": self.dataset[\"data\"][idx], \"condition\": self.dataset[\"condition\"][idx]}\n",
    "    \n",
    "    def get_normalizer(self, mode='limits', **kwargs):\n",
    "        data_normalizer = SingleFieldLinearNormalizer()\n",
    "        data_normalizer.fit(self.dataset[\"data\"], last_n_dims=1, mode='limits')\n",
    "\n",
    "        condition_normalizer = SingleFieldLinearNormalizer()\n",
    "        condition_normalizer.fit(self.dataset[\"condition\"], last_n_dims=1, mode='limits')\n",
    "\n",
    "        normalizer = LinearNormalizer()\n",
    "        normalizer[\"data\"] = data_normalizer\n",
    "        normalizer[\"condition\"] = condition_normalizer\n",
    "\n",
    "        return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the data\n",
    "Do = plot_data.shape[1]\n",
    "num_subplots = 16\n",
    "num_column = int(np.sqrt(num_subplots))+1\n",
    "# num_column = 15\n",
    "num_row = (int((num_subplots)/num_column)+1)\n",
    "\n",
    "plt.figure(figsize=(5*num_column, 5*num_row))\n",
    "plot_iter = 0\n",
    "for i in range(num_row):\n",
    "    for j in range(num_column):\n",
    "        plt.subplot(num_row, num_column, i*num_column+j+1)\n",
    "        \n",
    "        # plt.scatter(dataset.dataset.replay_buffer['obs'][:, (plot_iter)%(D-1)],\n",
    "        #             dataset.dataset.replay_buffer['obs'][:, (plot_iter)%(D-1)+1])\n",
    "        \n",
    "        plt.scatter(plot_data[:, (plot_iter)], plot_data[:, (plot_iter+1)], s=2)\n",
    "        plt.xlabel(f\"x_{(plot_iter)}\")\n",
    "        plt.ylabel(f\"x_{(plot_iter)}\")\n",
    "        plt.grid(True)\n",
    "        plot_iter += 1\n",
    "        \n",
    "        if (plot_iter)+1 == Do:\n",
    "            break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot the condition\n",
    "Da = plot_condition.shape[1]\n",
    "num_subplots = Da-1\n",
    "num_column = int(np.sqrt(num_subplots))+1\n",
    "num_row = (int((num_subplots)/num_column)+1)\n",
    "\n",
    "plt.figure(figsize=(5*num_column, 5*num_row))\n",
    "plot_iter = 0\n",
    "for i in range(num_row):\n",
    "    for j in range(num_column):\n",
    "        plt.subplot(num_row, num_column, i*num_column+j+1)\n",
    "        \n",
    "        plt.scatter(plot_condition[:, (plot_iter)], plot_condition[:, (plot_iter)+1], s=1)\n",
    "        plt.xlabel(f\"x_{(plot_iter)}\")\n",
    "        plt.ylabel(f\"x_{(plot_iter)+1}\")\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plot_iter += 1\n",
    "        if (plot_iter)+1 == Da:\n",
    "            break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianFourierProjection(nn.Module):\n",
    "  \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "  def __init__(self, embed_dim, scale=30.):\n",
    "    super().__init__()\n",
    "    # Randomly sample weights during initialization. These weights are fixed \n",
    "    # during optimization and are not trainable.\n",
    "    self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "  def forward(self, x):\n",
    "    x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "  \"\"\"A fully connected layer that reshapes outputs to feature maps.\"\"\"\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super().__init__()\n",
    "    self.dense = nn.Linear(input_dim, output_dim)\n",
    "  def forward(self, x):\n",
    "    return self.dense(x)[..., None]\n",
    "\n",
    "\n",
    "class ScoreNet(nn.Module):\n",
    "  \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
    "\n",
    "  def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256, 512, 1024], embed_dim=256):\n",
    "    \"\"\"Initialize a time-dependent score-based network.\n",
    "\n",
    "    Args:\n",
    "      marginal_prob_std: A function that takes time t and gives the standard\n",
    "        deviation of the perturbation kernel p_{0t}(x(t) | x(0)).\n",
    "      channels: The number of channels for feature maps of each resolution.\n",
    "      embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    # Gaussian random feature embedding layer for time\n",
    "    self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "         nn.Linear(embed_dim, embed_dim))\n",
    "    # Encoding layers where the resolution decreases\n",
    "    kernel_size = 3\n",
    "    self.conv1 = nn.Conv1d(2, channels[0], kernel_size=kernel_size, stride=1, bias=False)\n",
    "    self.dense1 = Dense(embed_dim, channels[0])\n",
    "    self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "\n",
    "    self.conv2 = nn.Conv1d(channels[0], channels[1], kernel_size=kernel_size, stride=2, bias=False)\n",
    "    self.dense2 = Dense(embed_dim, channels[1])\n",
    "    self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "\n",
    "    self.conv3 = nn.Conv1d(channels[1], channels[2], kernel_size=kernel_size, stride=2, bias=False)\n",
    "    self.dense3 = Dense(embed_dim, channels[2])\n",
    "    self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "\n",
    "    self.conv4 = nn.Conv1d(channels[2], channels[3], kernel_size=kernel_size, stride=2, bias=False)\n",
    "    self.dense4 = Dense(embed_dim, channels[3])\n",
    "    self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])\n",
    "\n",
    "    self.conv5 = nn.Conv1d(channels[3], channels[4], kernel_size=kernel_size, stride=2, bias=False)\n",
    "    self.dense5 = Dense(embed_dim, channels[4])\n",
    "    self.gnorm5 = nn.GroupNorm(32, num_channels=channels[4])\n",
    "\n",
    "    self.conv6 = nn.Conv1d(channels[4], channels[5], kernel_size=kernel_size, stride=2, bias=False)\n",
    "    self.dense6 = Dense(embed_dim, channels[5])\n",
    "    self.gnorm6 = nn.GroupNorm(32, num_channels=channels[5])\n",
    "\n",
    "    # Decoding layers where the resolution increases\n",
    "    self.tconv6 = nn.ConvTranspose1d(channels[5], channels[4], kernel_size=kernel_size, stride=2, bias=False)\n",
    "    self.dense7 = Dense(embed_dim, channels[4])\n",
    "    self.tgnorm6 = nn.GroupNorm(32, num_channels=channels[4])\n",
    "    \n",
    "    self.tconv5 = nn.ConvTranspose1d(channels[4] + channels[4], channels[3], kernel_size=kernel_size, stride=2, bias=False, output_padding=1)\n",
    "    self.dense8 = Dense(embed_dim, channels[3])\n",
    "    self.tgnorm5 = nn.GroupNorm(32, num_channels=channels[3])\n",
    "\n",
    "    self.tconv4 = nn.ConvTranspose1d(channels[3] + channels[3], channels[2], kernel_size=kernel_size, stride=2, bias=False)\n",
    "    self.dense9 = Dense(embed_dim, channels[2])\n",
    "    self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "\n",
    "    self.tconv3 = nn.ConvTranspose1d(channels[2] + channels[2], channels[1], kernel_size=kernel_size, stride=2, bias=False)\n",
    "    self.dense10 = Dense(embed_dim, channels[1])\n",
    "    self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "    \n",
    "    self.tconv2 = nn.ConvTranspose1d(channels[1] + channels[1], channels[0], kernel_size=kernel_size, stride=2, bias=False)\n",
    "    self.dense11 = Dense(embed_dim, channels[0])\n",
    "    self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
    "    \n",
    "    self.tconv1 = nn.ConvTranspose1d(channels[0] + channels[0], 2, kernel_size=kernel_size, stride=1)\n",
    "    \n",
    "    # The swish activation function\n",
    "    self.act = lambda x: x * torch.sigmoid(x)\n",
    "    self.marginal_prob_std = marginal_prob_std\n",
    "  \n",
    "  def forward(self, x, t): \n",
    "    # Obtain the Gaussian random feature embedding for t   \n",
    "    embed = self.act(self.embed(t))    \n",
    "    # Encoding path\n",
    "    h1 = self.conv1(x)    \n",
    "    ## Incorporate information from t\n",
    "    h1 += self.dense1(embed)\n",
    "    ## Group normalization\n",
    "    h1 = self.gnorm1(h1)\n",
    "    h1 = self.act(h1)\n",
    "\n",
    "    h2 = self.conv2(h1)\n",
    "    h2 += self.dense2(embed)\n",
    "    h2 = self.gnorm2(h2)\n",
    "    h2 = self.act(h2)\n",
    "    \n",
    "    h3 = self.conv3(h2)\n",
    "    h3 += self.dense3(embed)\n",
    "    h3 = self.gnorm3(h3)\n",
    "    h3 = self.act(h3)\n",
    "    \n",
    "    h4 = self.conv4(h3)\n",
    "    h4 += self.dense4(embed)\n",
    "    h4 = self.gnorm4(h4)\n",
    "    h4 = self.act(h4)\n",
    "    \n",
    "    h5 = self.conv5(h4)\n",
    "    h5 += self.dense5(embed)\n",
    "    h5 = self.gnorm5(h5)\n",
    "    h5 = self.act(h5)\n",
    "\n",
    "    h6 = self.conv6(h5)\n",
    "    h6 += self.dense6(embed)\n",
    "    h6 = self.gnorm6(h6)\n",
    "    h6 = self.act(h6)\n",
    "\n",
    "    # Decoding path\n",
    "    h = self.tconv6(h6)\n",
    "    h += self.dense7(embed)\n",
    "    h = self.tgnorm6(h)\n",
    "    h = self.act(h)\n",
    "\n",
    "    h = self.tconv5(torch.cat([h, h5], dim=1))\n",
    "    h += self.dense8(embed)\n",
    "    h = self.tgnorm5(h)\n",
    "    h = self.act(h)\n",
    "\n",
    "    h = self.tconv4(torch.cat([h, h4], dim=1))\n",
    "    h += self.dense9(embed)\n",
    "    h = self.tgnorm4(h)\n",
    "    h = self.act(h)\n",
    "    \n",
    "    h = self.tconv3(torch.cat([h, h3], dim=1))\n",
    "    h += self.dense10(embed)\n",
    "    h = self.tgnorm3(h)\n",
    "    h = self.act(h)\n",
    "    \n",
    "    h = self.tconv2(torch.cat([h, h2], dim=1))\n",
    "    h += self.dense11(embed)\n",
    "    h = self.tgnorm2(h)\n",
    "    h = self.act(h)\n",
    "    \n",
    "    h = self.tconv1(torch.cat([h, h1], dim=1))\n",
    "\n",
    "    # Normalize output\n",
    "    h = h / self.marginal_prob_std(t)[:, None, None]\n",
    "    return h\n",
    "  \n",
    "class TransformerScoreNet(nn.Module):\n",
    "  def __init__(self, input_dim, marginal_prob_std, embed_dim=128, num_heads=4, num_layers=4, ff_dim=256, dropout=0.1):\n",
    "      super().__init__()\n",
    "      self.input_dim = input_dim\n",
    "      self.marginal_prob_std = marginal_prob_std\n",
    "      # Temporal embedding\n",
    "      self.time_embed = nn.Sequential(\n",
    "          GaussianFourierProjection(embed_dim),\n",
    "          nn.Linear(embed_dim, embed_dim),\n",
    "          nn.ReLU(),\n",
    "          nn.Linear(embed_dim, embed_dim)\n",
    "      )\n",
    "\n",
    "      # Input projection\n",
    "      self.input_proj = nn.Linear(input_dim, embed_dim)\n",
    "\n",
    "      # Transformer encoder\n",
    "      encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim, dropout=dropout, batch_first=True)\n",
    "      self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "      # Output projection\n",
    "      self.output_proj = nn.Linear(embed_dim, input_dim)\n",
    "\n",
    "  def forward(self, x, t):\n",
    "      \"\"\"\n",
    "      Args:\n",
    "          x: Tensor of shape (B, L, D)\n",
    "          t: Tensor of shape (B,) or (B, 1)\n",
    "      Returns:\n",
    "          score: Tensor of shape (B, L, D)\n",
    "      \"\"\"\n",
    "      B, L, D = x.shape\n",
    "\n",
    "      # Project input\n",
    "      x_proj = self.input_proj(x)  # (B, L, embed_dim)\n",
    "\n",
    "      # Get time embeddings and expand across sequence\n",
    "      t_embed = self.time_embed(t).unsqueeze(1)  # (B, 1, embed_dim)\n",
    "      t_embed = t_embed.expand(-1, L, -1)        # (B, L, embed_dim)\n",
    "\n",
    "      # Combine with input\n",
    "      x_combined = x_proj + t_embed              # (B, L, embed_dim)\n",
    "\n",
    "      # Transformer forward\n",
    "      h = self.transformer(x_combined)           # (B, L, embed_dim)\n",
    "\n",
    "      # Project back to input dimension\n",
    "      out = self.output_proj(h)                  # (B, L, D)\n",
    "      # Normalize output\n",
    "      out = out / self.marginal_prob_std(t)[:, None, None]\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:1' #@param ['cuda', 'cpu'] {'type':'string'}\n",
    "\n",
    "def marginal_prob_std(t, sigma):\n",
    "  \"\"\"Compute the mean and standard deviation of $p_{0t}(x(t) | x(0))$.\n",
    "\n",
    "  Args:    \n",
    "    t: A vector of time steps.\n",
    "    sigma: The $\\sigma$ in our SDE.  \n",
    "  \n",
    "  Returns:\n",
    "    The standard deviation.\n",
    "  \"\"\"    \n",
    "  t = torch.tensor(t, device=device)\n",
    "  return torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma))\n",
    "\n",
    "def diffusion_coeff(t, sigma):\n",
    "  \"\"\"Compute the diffusion coefficient of our SDE.\n",
    "\n",
    "  Args:\n",
    "    t: A vector of time t.\n",
    "    sigma: The $\\sigma$ in our SDE.\n",
    "  \n",
    "  Returns:\n",
    "    The vector of diffusion coefficients.\n",
    "  \"\"\"\n",
    "  return torch.tensor(sigma**t, device=device)\n",
    "  \n",
    "sigma =  50.0#@param {'type':'number'}\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the loss function (double click to expand or collapse)\n",
    "def loss_fn(model, x, marginal_prob_std, eps=1e-4):\n",
    "  \"\"\"The loss function for training score-based generative models.\n",
    "\n",
    "  Args:\n",
    "    model: A PyTorch model instance that represents a \n",
    "      time-dependent score-based model.\n",
    "    x: A mini-batch of training data.    \n",
    "    marginal_prob_std: A function that gives the standard deviation of \n",
    "      the perturbation kernel.\n",
    "    eps: A tolerance value for numerical stability.\n",
    "  \"\"\"\n",
    "  random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps  \n",
    "  z = torch.randn_like(x)\n",
    "  std = marginal_prob_std(random_t).reshape(-1, *[1 for _ in range( x.ndim-1)])\n",
    "  perturbed_x = x + z * std\n",
    "\n",
    "  # int_time = (random_t*100).to(torch.int32)\n",
    "  # score = model(perturbed_x, int_time, condition)\n",
    "  score = model(perturbed_x, random_t)\n",
    "  loss = torch.mean(torch.sum((score * std + z)**2, dim=(1)))\n",
    "  return loss\n",
    "\n",
    "def loss_fn_fixed_time(model, x, marginal_prob_std, time):\n",
    "  time = torch.max(time, torch.tensor(1e-3))\n",
    "  time = torch.fill(torch.zeros(x.shape[0], device=x.device), time)\n",
    "  z = torch.randn_like(x)\n",
    "  std = marginal_prob_std(time).reshape(-1, *[1 for _ in range( x.ndim-1)])\n",
    "  perturbed_x = x + z * std\n",
    "  normalized_score = model(perturbed_x, time)\n",
    "  loss = torch.mean(torch.sum((normalized_score * std + z)**2, dim=(1)))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Do: {Do}, Da: {Da}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dimensionality\n",
    "# score_model = ConditionalUnet1D(\n",
    "#     input_dim=2,\n",
    "#     global_cond_dim=None,\n",
    "#     cond_predict_scale=True,\n",
    "#     down_dims=[256,512,1024],\n",
    "#     kernel_size=3,\n",
    "#     n_groups=8,\n",
    "# )\n",
    "# Make score net and data loader\n",
    "image_dataset = ImageDatasetWrapper(data_dict)\n",
    "image_dataloader = DataLoader(image_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "score_model = ScoreNet(\n",
    "    marginal_prob_std=marginal_prob_std_fn\n",
    ")\n",
    "# score_model = TransformerScoreNet(\n",
    "#     input_dim=1,\n",
    "#     marginal_prob_std=marginal_prob_std_fn,\n",
    "# )\n",
    "score_model.to(device)\n",
    "\n",
    "data = next(iter(image_dataloader))\n",
    "x = normalizer['data'].normalize(data['data']).reshape(data['data'].shape[0], -1, 2).permute(0, 2, 1).to(device)\n",
    "# x = x.reshape(data['data'].shape[0], -1, 2).to(device)\n",
    "# x = torch.randn(128, D, 2, device=device)\n",
    "# condition = normalizer['condition'].normalize(data['condition']).to(device)\n",
    "t = torch.ones(x.shape[0],  device=device)\n",
    "# score = score_model(x, t, condition=condition)\n",
    "# x = x.unsqueeze(1)\n",
    "print(x.shape)\n",
    "score = score_model(x, t)\n",
    "# score = score_model(x, t, global_cond=None)\n",
    "print(f\"score.shape = {score.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_model = ScoreNet(\n",
    "    marginal_prob_std=marginal_prob_std_fn\n",
    ")\n",
    "# score_model = TransformerScoreNet(\n",
    "#     input_dim=1,\n",
    "#     marginal_prob_std=marginal_prob_std_fn,\n",
    "# )\n",
    "score_model.to(device)\n",
    "\n",
    "n_epochs = 50\n",
    "## learning rate\n",
    "lr=1e-3\n",
    "optimizer = Adam(score_model.parameters(), lr=lr)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs*len(image_dataloader), eta_min=0.0)\n",
    "tqdm_bar = tqdm(range(n_epochs))\n",
    "\n",
    "lr_ls = list()\n",
    "for epoch in tqdm_bar:\n",
    "  \n",
    "  avg_loss = 0.\n",
    "  avg_sde_loss = 0.\n",
    "  num_items = 0\n",
    "  for data in image_dataloader:\n",
    "    x = normalizer['data'].normalize(data['data']).reshape(data['data'].shape[0], -1, 2).permute(0, 2, 1).to(device)\n",
    "    # y = normalizer['condition'].normalize(data['condition']).to(device)\n",
    "    \n",
    "    # conditional_loss = loss_fn(score_model, x, y, marginal_prob_std_fn, eps=1e-3)\n",
    "    unconditional_loss = loss_fn(score_model, x, marginal_prob_std_fn, eps=1e-5)\n",
    "    # fixed_time_loss_unconditional = loss_fn_fixed_time(score_model, x, marginal_prob_std_fn, torch.tensor(1e-3))\n",
    "    # fixed_time_loss_conditional = loss_fn_fixed_time(score_model, x, y, marginal_prob_std_fn, torch.tensor(1e-3))\n",
    "    \n",
    "    # loss = conditional_loss + unconditional_loss #+ 0.00 * (fixed_time_loss_conditional + fixed_time_loss_unconditional)\n",
    "    loss = unconditional_loss\n",
    "    # dsm_loss = fixed_time_loss_conditional + fixed_time_loss_unconditional\n",
    "    # sde_loss = conditional_loss + unconditional_loss\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    avg_loss += loss.item() * x.shape[0]\n",
    "    # avg_sde_loss += sde_loss.item() * x.shape[0]\n",
    "    num_items += x.shape[0]\n",
    "    \n",
    "  # Print the averaged training loss so far.\n",
    "  tqdm_bar.set_description(desc=f'Average Loss: {avg_loss / num_items:.5f}')\n",
    "  print(f\"Epoch {epoch} / {n_epochs}:{avg_loss / num_items:.5f} / lr:{scheduler.get_last_lr()} / sde_loss:{avg_sde_loss / num_items:.5f}\")\n",
    "  # Update the checkpoint after each epoch of training.\n",
    "  torch.save(score_model.state_dict(), 'ckpt.pth')\n",
    "  lr_ls.append(scheduler.get_last_lr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Define the Euler-Maruyama sampler (double click to expand or collapse)\n",
    "\n",
    "## The number of sampling steps.\n",
    "num_steps =  500#@param {'type':'integer'}\n",
    "def Euler_Maruyama_sampler(score_model,\n",
    "                           marginal_prob_std,\n",
    "                           diffusion_coeff, \n",
    "                           batch_size=64, \n",
    "                           num_steps=num_steps, \n",
    "                           device='cuda', \n",
    "                           eps=1e-3,\n",
    "                           z = None):\n",
    "  \"\"\"Generate samples from score-based models with the Euler-Maruyama solver.\n",
    "\n",
    "  Args:\n",
    "    score_model: A PyTorch model that represents the time-dependent score-based model.\n",
    "    marginal_prob_std: A function that gives the standard deviation of\n",
    "      the perturbation kernel.\n",
    "    diffusion_coeff: A function that gives the diffusion coefficient of the SDE.\n",
    "    batch_size: The number of samplers to generate by calling this function once.\n",
    "    num_steps: The number of sampling steps. \n",
    "      Equivalent to the number of discretized time steps.\n",
    "    device: 'cuda' for running on GPUs, and 'cpu' for running on CPUs.\n",
    "    eps: The smallest time step for numerical stability.\n",
    "  \n",
    "  Returns:\n",
    "    Samples.    \n",
    "  \"\"\"\n",
    "  t = torch.ones(batch_size, device=device)\n",
    "  print(f\"marginal_prob_std(t).shape: {marginal_prob_std(t).shape}\")\n",
    "  print(f\"torch.randn(batch_size, Do, device=device).shape: {torch.randn(batch_size, Do, device=device).shape}\")\n",
    "  \n",
    "  \n",
    "  if z is None:\n",
    "    init_x = torch.randn(batch_size, 2, 137, device=device) \\\n",
    "      * marginal_prob_std(t)[:, None, None]\n",
    "  else:\n",
    "    init_x = z\n",
    "  time_steps = torch.linspace(1., eps, num_steps, device=device)\n",
    "  step_size = time_steps[0] - time_steps[1]\n",
    "  x = init_x\n",
    "  tqdm_bar = tqdm(time_steps)\n",
    "  with torch.no_grad():\n",
    "    for time_step in tqdm_bar:      \n",
    "      batch_time_step = torch.ones(batch_size, device=device) * time_step\n",
    "      g = diffusion_coeff(batch_time_step)\n",
    "      score_batch_time_step = batch_time_step\n",
    "      # score_batch_time_step = (batch_time_step*100).to(dtype=torch.int32)\n",
    "      mean_x = x + (g**2)[:, None, None] * score_model(x, score_batch_time_step) * step_size\n",
    "      x = mean_x + torch.sqrt(step_size) * g[:, None, None] * torch.randn_like(x)      \n",
    "  # Do not include any noise in the last sampling step.\n",
    "  return mean_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Load the pre-trained checkpoint from disk.\n",
    "# device = 'cuda' #@param ['cuda', 'cpu'] {'type':'string'}\n",
    "# ckpt = torch.load('ckpt.pth', map_location=device)\n",
    "# score_model.load_state_dict(ckpt)\n",
    "# condition = torch.tensor([[0.0, 0.0]])\n",
    "idx = torch.randint(0, len(image_dataset), size=(1,))\n",
    "gt_data = image_dataset[idx]\n",
    "condition = normalizer['condition'].normalize(gt_data['condition'])\n",
    "condition = None\n",
    "gt_data = gt_data['data']\n",
    "\n",
    "if condition is None:\n",
    "  sample_batch_size = 10000\n",
    "else:\n",
    "  sample_batch_size = 256\n",
    "\n",
    "if condition is None:\n",
    "  sampling_condition = None\n",
    "else:\n",
    "  sampling_condition = condition.repeat(sample_batch_size, 1).to(device)\n",
    "\n",
    "sampler = Euler_Maruyama_sampler\n",
    "#@param ['Euler_Maruyama_sampler', 'pc_sampler', 'ode_sampler'] {'type': 'raw'}\n",
    "\n",
    "data = next(iter(image_dataloader))\n",
    "data_dim = data['data'].shape[1:]\n",
    "\n",
    "## Generate samples using the specified sampler.\n",
    "samples = sampler(score_model,\n",
    "                  marginal_prob_std_fn,\n",
    "                  diffusion_coeff_fn, \n",
    "                  sample_batch_size, \n",
    "                  device=device,\n",
    "                  ).detach().cpu().squeeze().permute(0, 2, 1).reshape(sample_batch_size, -1)\n",
    "\n",
    "unnormalized_samples = normalizer['data'].unnormalize(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"gt_data.shape: {gt_data.shape} | gt_condition.shape: {condition.shape if condition is not None else None}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     scores_on_sampled_samples = score_model(samples.to(device).unsqueeze(-1), torch.ones(samples.shape[0], device=device)*1e-3).squeeze(-1).detach().cpu().numpy()\n",
    "#     scores_on_training_data = score_model(torch.tensor(plot_data).to(device).unsqueeze(-1), torch.ones(plot_data.shape[0], device=device)*1e-3).squeeze(-1).detach().cpu().numpy()\n",
    "\n",
    "# print(scores_on_sampled_samples.shape)\n",
    "# print(scores_on_training_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subplots = Do-1\n",
    "num_subplots = 273\n",
    "Do = 273\n",
    "num_column = int(np.sqrt(num_subplots))+1\n",
    "num_row = (int((num_subplots)/num_column)+1)\n",
    "\n",
    "plt.figure(figsize=(5*num_column, 5*num_row))\n",
    "plot_iter = 0\n",
    "for i in range(num_row):\n",
    "    for j in range(num_column):\n",
    "        plt.subplot(num_row, num_column, i*num_column+j+1)\n",
    "        \n",
    "        plt.scatter(plot_data[:, (plot_iter)%(Do-1)], plot_data[:, (plot_iter)%(Do-1)+1], s=2)\n",
    "        plt.scatter(samples[:, (plot_iter)%(Do-1)], samples[:, (plot_iter)%(Do-1)+1], alpha=0.3, s=2)\n",
    "        # plt.quiver(plot_data[:, (plot_iter)%(Do-1)], plot_data[:, (plot_iter)%(Do-1)+1], scores_on_training_data[:, (plot_iter)%(Do-1)], scores_on_training_data[:, (plot_iter)%(Do-1)+1], scale=1000)\n",
    "        # plt.scatter(gt_data[(plot_iter)%(Do-1)], gt_data[(plot_iter)%(Do-1)+1], marker='*', color='red', s=50)\n",
    "        plt.xlabel(f\"x_{(plot_iter)%(Do-1)}\")\n",
    "        plt.ylabel(f\"x_{(plot_iter)%(Do-1)+1}\")\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plot_iter += 1\n",
    "        \n",
    "        if (plot_iter)+1 == Do:\n",
    "            plot_iter = 0\n",
    "            break \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def langevin_mcmc(x, score_model, n_steps, step_scale=0.001, t=1e-3):\n",
    "    # Langevin MCMC sampling (No rejection)\n",
    "    step_size = step_scale \n",
    "    noise = torch.randn_like(x).to(x.device) * np.sqrt(2*step_size)\n",
    "    batch_t = torch.ones(x.shape[0], device=x.device) * t\n",
    "\n",
    "    for _ in tqdm(range(n_steps)):\n",
    "        with torch.no_grad():\n",
    "            score = score_model(x, batch_t)\n",
    "            x = x + step_size * score + noise\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch_size=5000\n",
    "sample_dataset_loader = DataLoader(image_dataset, batch_size=sample_batch_size, shuffle=True)\n",
    "\n",
    "data = next(iter(sample_dataset_loader))\n",
    "initial_x = (normalizer['data'].normalize(data['data']) + torch.randn_like(data['data'])).unsqueeze(1).to(device) * 0.00\n",
    "samples = langevin_mcmc(initial_x, score_model, n_steps=100, step_scale=0.001, t=1e-3).squeeze(1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subplots = Do-1\n",
    "num_subplots = 16\n",
    "num_column = int(np.sqrt(num_subplots))+1\n",
    "num_row = (int((num_subplots)/num_column)+1)\n",
    "\n",
    "plt.figure(figsize=(5*num_column, 5*num_row))\n",
    "plot_iter = 0\n",
    "for i in range(num_row):\n",
    "    for j in range(num_column):\n",
    "        plt.subplot(num_row, num_column, i*num_column+j+1)\n",
    "        \n",
    "        plt.scatter(plot_data[:, (plot_iter)%(Do-1)], plot_data[:, (plot_iter)%(Do-1)+1], s=2)\n",
    "        plt.scatter(samples[:, (plot_iter)%(Do-1)], samples[:, (plot_iter)%(Do-1)+1], alpha=0.3, s=2)\n",
    "        # plt.scatter(gt_data[(plot_iter)%(Do-1)], gt_data[(plot_iter)%(Do-1)+1], marker='*', color='red', s=50)\n",
    "        plt.xlabel(f\"x_{(plot_iter)%(Do-1)}\")\n",
    "        plt.ylabel(f\"x_{(plot_iter)%(Do-1)+1}\")\n",
    "        # plt.xlim([-1.1, 1.1])\n",
    "        # plt.ylim([-1.1, 1.1])\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plot_iter += 1\n",
    "        \n",
    "        if (plot_iter)+1 == Do:\n",
    "            plot_iter = 0\n",
    "            break \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Do you like this? Then save it!\n",
    "# torch.save(score_model.state_dict(), 'score_with_trajectory_condition.pth')\n",
    "# torch.save(normalizer.state_dict(), 'normalizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_normalizer = LinearNormalizer()\n",
    "dummy_normalizer.load_state_dict(normalizer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
